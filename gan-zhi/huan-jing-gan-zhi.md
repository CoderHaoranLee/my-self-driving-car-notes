##### 环境感知是自动驾驶的基本功能，它为车辆提供了驾驶环境的关键信息，包括可行驶区域和周围障碍物的位置，速度，甚至对它们未来状态的预测。环境感知的传感器基本依赖于Lidar，摄像头或者是二者的融合。一些传统的方法也使用了短距和长距雷达以及超声波传感器。不管使用什么传感器，感知任务的两个关键部分为（i）路面检测和（ii）路上物体检测。

### LIDAR

Lidar\(light detection and ranging device\), 每秒会发射几百万个光脉冲用于探测距离。通过旋转发射光脉冲主轴，可以绘制环境的动态三维地图。Lidar是现有大多数自动驾驶汽车物体检测的核心。图3是3D Lidar理想情况下物体检测的结果，所有的移动物体都被识别出来。

在实际中，Lidar返回的点不可能是完美的。处理这些Lidar点的主要难点在于扫描点比较稀疏，点有缺失，以及散乱的模式。 再加上环境中表面的任意性和不规则性也对感知增加了更多的挑战。有时候在这些可视化后的扫描点中提取出有用的信息对人来说也是非常困难的。

### 表示（representation）

Lidar输出的是从物体上反射回来的稀疏的三维点，每个点对应物体表面相对于Lidar的三维空间位置。这些点的表示方式主要有三种，包括点云，特征（features），栅格（grids）。

基于点云的方法是直接使用传感器的原始数据以进行下一步的处理，这种方法是一种很好的环境表示方式，但是会增加处理数据的时间以及降低内存效率。为了缓和这种缺点，经常会使用基于体素（voxel-based）的滤波方法对原始点云数据进行滤波以减少点的数量。

基于特征的方法是从点云中提取参数化的特征，利用这些提取的特征来表示环境。这些特征通常包含直线和平面。这种方法是存储高效的，特征也经常比较抽象，这种表示方法的精度取决于点云的形状（nature），因为并不是所有的环境特征都能够很好的被表示。

基于网格的方法是将空间离散化成许多小的网格，每个网格表示网格内点云的一些信息。这种方法是内存高效的，并且没有预先定义特征的限制。但是对于离散化网格的大小却不能一概而论。一种自适应八叉树（adaptive octree）的方法可以用于将粗糙的网格进行细化。

### 分割算法

为了理解3D点云信息，一般有两个步骤：分割和分类。为了提高精度和一致性，有时也会包含第三步，时域积分（time integration？）。点云分割是为了将点云聚集成多个群（groups），每个群里点云的性质是相同的。分类是识别这些被聚集成群的点云的类别，像自行车，汽车，行人，路面等。

根据综述文献\[30\]，点云分割算法可以分为5类：基于边缘的（edge based），基于区域的\(region based\)，基于属性的（attribute based），基于模型的（model based），基于图的（graph based）。本文将简略回顾这些领域进几年的发展。最后并引出了一个新的类别，基于深度学习算法的。

基于边缘的方法一般是用于一些物体有很明显的人工边缘特征的特殊任务，例如道路边缘检测。但是，对于一般的场景检测，该方法不太适合，并且该方法对噪声点敏感。为了提高算法的鲁棒性，通常会计算关键点的海拔梯度（elevation gradients），并且使用梯度滤波器滤除那些波动点。

基于区域的方法是利用区域生长的机制根据一些特定的准则（例如欧式距离，平面法向量等）将临近的点进行聚类。通常，该过程从一些种子点（seed points）开始，根据预设的准则进行区域扩张（生长）。相比基于边缘的方法，因为考虑了局部邻域的信息，该方法在实际中更有效。文献\[37\]提出了一种基于扫射线的算法可以找出局部最低点，并以该点作为区域增长的最低点并且根据斜率和海拔（slope and elevation）进行增长以进行地面分割。文献\[38\]先提取局部点云的法向量和平坦度，然后利用基于特征的方法进行增长以得到树和其他非平面区域的分割。为了使区域增长过程更鲁棒，文献\[34\]提出了一种自适应的欧式聚类（self-adaptive）的方法。文献\[39\]提出一种新的属性"不规则度（unevenness）"作为增长的准则，它是根据每个扫描束连续扫描距离的差计算得出。文献\[40-42\]指出该属性可以更好的检测到小物体，对地面的坡度，车辆的俯仰角和滚转角更不敏感。

在一些文献中，研究着通过采取一些启发式的方法来寻找更有效的产生种子点的方式，这些种子点可以使区域增长更高效和鲁棒。在文献\[43\]中，Vieira等人在选择种子点之前，先根据曲率去除一些分布在陡峭边缘上的点，因为一般好的种子点都是分布在区域内部（interior），而不是在边缘。在文献\[44\]中，先估计每个点的法向量（normal），然后选择具有最小残差的点作为种子点。文献\[28\]提出了一种多策略种子生成方法...

基于区域的分割方法在众多文献中广泛使用，但是这种方法分割的结果严重依赖于种子点的选择。差的种子点往往会导致不充分且低效分割，并且不同的种子点选择往往会导致不同的分割结果。此外，所有基于区域的方法对时间和内存等计算资源的要求都比较高。

基于模型的方法是将点云用一个预设的参数化的模型进行拟合。这些模型一般包括平面，球，圆锥体，圆柱体。这些模型一般都要有高效简洁的数学表达形式。可以拟合模型的内点被聚集在一起作为一个分割。大多数基于模型的方法都是用来进行地面分割的。有两种被广泛使用的模型拟合算法：RANSAC\(random sample consensus\)和HT\(Hough Transform\)。因此，基于模型的方法的优缺点和这两种算法的优缺点一致。

需要研究者根据平面假设，利用RANSAC算法对点云中的地面进行分割。然而对于一些不是平面的表面，例如起伏的路面，上坡，下坡，弓型路面（humps）等，该方法就无法拟合这些表面。

为了解决这些情况下的平面分割，Oniga等人利用RANSAC方法拟合二次形式的"平面"。然后利用区域增长的方法改善该二次平面的分割。Asvadi等人将本车前的区域划分成5个等距的子区域，然后利用最小二乘的方法分别拟合各个子区域。文献\[23\]提出了一种分段地面估计算法，该算法包含4步：切分\(slicing\)，门限（gating），平面拟合，验证。切分是将本车前的部分划分成点云数量相同的区域。门限步是根据距离四分点方法（interquartile range method）排除区域内的外点。然后利用RANSAC方法对每个区域内进行平面拟合，最后的验证是检查相邻两个平面的法向量和高度。

许多文献中也使用霍夫变换模型拟合的方法去拟合不同的模型，像平面模型，圆柱体和球型。在文献\[53,54\]中，3D 霍夫变换使用点和法向量来识别点云中的平面结构。文献\[55\]中，作者提出了一种序列霍夫变换（sequence HT）算法用于检测点云中的圆柱体。相比于传统的需要5D霍夫空间的检测方法，该方法降低了时间和空间复杂度。

像上面提到的，基于模型的方法能够很好的用来平面提取。一般来说，点云分割的第一步都是去除地面，然后其他像区域生长法，在此基础上对剩下的点云进行聚类。但是，基于模型的方法最大的问题是没有考虑邻域信息以及上下文信息（neighborhood and context information），它很有可能把一些随机点拟合成一个特殊模型。此外，该方法对点云的密度，位置精度和噪声比较敏感。

基于属性的方法一般来说有两步，第一步是计算每个点的属性，第二步是根据根据这些属性对点进行聚类。As mentioned in \[30\], this set of methods allow for more cues to be incorporated into the formulation on top spatial information. 但是分割成功的关键仍然在于隐含的属性。

除了文献\[30\]中提到的一些方法，文献\[56\]中提到的基于属性的方法可以分割木棍状的物体，这种分割任务由于比较细窄，往往比较困难。在这种算法中，先确定最有临近点数量的大小。然后根据临近点的信息，利用主成分分析（PCA）的方法提取该点的几何特征（geometric），然后将该特征作为输入，利用LIBSVM把每个点增加3类属性（直线，平面和球）。最后根据这些关联的属性对点进行分割。

文献经常使用的另一种方法是基于图的方法。这种方法将点云数据转换成图的结构，其中每个点作为图中的节点/顶点，相邻的点相互连接构成图中的边。由于基于图的方法可以考虑局部和全局的线索，以及局部的信息，纹理，平滑度等其他特征，可以在全局的范围内进行优化，因此在图像语义分割中有较好的效果。

根据图像分割中的图割方法，在点云分割领域，也有一些研究者使用条件随机场（Conditional Random Field）或马尔可夫随机场（Markov Random Field）以及通过最大流最小割等方法进行点云处理研究。

在文献\[59,60\]中，作者第一次使用K近邻图，assigned each node according to a background penalty function, added hard foreground constraints, 再通过最小割的方法进行前景和背景的分割。Moosmann等人根据局部凸性测量利用基于图的方法进行了地面和物体的分割。

基于图的方法也常常被用于Lidar和视觉数据融合。相比于其他方法，由于其全局优化的特性，基于图的方法在处理复杂场景下往往鲁棒性更好。这种方法的主要问题在于时间花销比较大，尤其是在优化部分。

由于最近机器学习在计算机视觉领域的发展，一些研究人员开始考虑如何将2D图像中的机器学习框架应用到3D点云的分割和检测中。文献\[61\]是比较常用的数据集。

在文献\[62\]中，作者使用了随机森林分类器将每个点分到一个语义类。该分类器是基于light-weight 3D features进行训练的。之后，通过检测语义结构的不同来区分各自的外观（individual facades）。为了提高内存效率和分割精度，Riegler提出了一种基于八叉树网络（Octree Network based）的3D卷基。该方法利用了点云的稀疏性，并且注重内存分配和计算能力，以使网络足够深而又不用对分辨率进行折中。

这些方法是最近发展不久的，在实时应用上还有一些问题，但是这些方法对点云分割问题提供了一个新的视角。像检测算法中提到一样，这些方法可以对检测和分割算法进行整合。

### 检测算法

分割之后，每个聚集的点云簇都需要划分到不同的类别。每个点云簇包含的信息主要是点的空间信息和每个点的反射强度，这些信息对于物体识别来说太少了。有些研究者将视觉的数据和点云数据融合之后做识别，也有也有一些研究者直接利用点云做物体识别。

文献\[25\]中，作者用一个分类器来识别地面。For each segment, a histogram over all the surface normal vectors' height values was generated, and if the last bin contained the most votes, that segment was classified as ground. 该算法不能区分地面上的物体。

zhang等人利用支撑向量机做分类器，可以区分地面，植物，建筑，电线，和车辆。他们提取了点云的13个特征作为分类器的输入。但是，这个分类器仍然比较粗糙，在自动驾驶中不能很好的使用。

相比于前面提到的几种方法，最近发展的机器学习算法在识别任务上更稳定。在文献\[65\]中提出了VoxNet方法，该方法利用3D卷积进行点云分类。文献\[66\]提出了一种基于容量的3D卷积网络，并且introducing auxiliary learning tasks on part of an object and combining data augmentation with multi-orientation pooling. 文献\[67\]提出了一种3D卷积深度置信网络可以学习到不同类别任意姿态复杂3D形状的分布。

然而，就像文献\[63\]中提到的，对于3D网络，计算和内存需求是随点云尺寸呈立方增加。八叉树网络是一种比较高效的结构。

### 深度学习在点云分割和分类中的应用

* 栅格化

3D shape network -&gt; voxnet -&gt; vote3deep  
由于点云数据的非结构化特性，使得卷积操作难以直接用到点云上。"3D ShapeNets: A Deep Representation for Volumetric Shapes"一文将点云数据进行结构化，其方法是将三维空间进行栅格化，统计每个小栅格中包含点的个数以确定该栅格是否被占据。  
![](/assets/20160519113536667)  
在栅格化后的数据基础上，进行3DCNN操作实现点云分类。这个方法的问题也是非常明显的，栅格化的分辨率对计算量以及存储空间的影响非常大。voxnet采用了一种稀疏栅格方法对点云数据进行结构化，然后利用3DCNN对栅格化后的数据进行处理。由于点云的稀疏性，对数据的栅格化会增加很多没有被点云占据的栅格，而在进行卷积计算是，这些栅格既浪费时间又对结果没有明显改善。Martin等人提出了vote3deep, 采用投票操作代替了卷积操作，且证明了该投票操作和卷积操作的等价性。但是投票的前提也是需要对空间进行栅格化。

* 投影

MVCNN  
3D FCN -&gt; MV3D  
deep semantic classification

另一种将点云数据结构化的方式是对数据进行投影。H.Su等人MVCNN方法，该方法对点云物体进行视角投影（拍摄）得到二维图像，将这些图像作为传统CNN网络的输入，最后做一个视角pooling，得到该点云的综合特征以进\`行物体分类。  
![](/assets/20160519122208264)  
这种方法的问题在于当点云数据是由单一视角扫描得到，如Lidar，该扫描方式并不能得到物体完整形状的三维数据，此时进行多视角投影在一些视角上的投影图并不能很好的反映物体。针对Lidar这种传感器产生的3D点云，Bo Li等人提出了2种投影图的构建方式，并利用全卷积网络以2种投影图作为输入，实现点云中的车辆检测。Xiaozhi Chen等人提出MV3D network，利用该投影方法得到的投影图与摄像头图像进行融合，提高车辆检测的精度。采用投影的方式对点云数据进行结构化，使其可以直接借用图像领域的检测方法进行目标检测，但是该方法对数据进行了压缩，损失了点与点之间的空间结构信息。此外该方法难以完成点云分割。

* 直接处理

deep Kd-Networks  
pointnet  
pointnet++

Charles R.Qi等人提出了PointNet方法，该方法可以直接处理点云数据。该方法的核心思想是将每个点作为一个多层感知机输入，同一层所有点对应的多层感知机之间参数共享，这类似于图像中的1X1的卷积层。采用max pooling提取整个点云的全局特征。该方法在分类和分割精度上都取得了较好的结果。该方法的问题在于多层感知机提取特征时，只考虑了单一点，并没有考虑临近点，因此无法提取点云的局部特征。因此，他们又提出了PointNet++。该方法是使用PointNet方法对局部点云进行处理，用max pooling提取到局部特征。相对于PointNet该方法的精度有明显的提高。Roman Klokov等人提出了Deep Kd-Networks也可以接受原始点云数据的输入。该方法使用kd树对点云进行序列化，序列化后相邻两个点合并到一起作为感知机的输入，并且kd树同一层节点对应的感知机其参数是共享的，该操作也是模仿了图像卷积的操作。

### 视觉
自动驾驶中的视觉系统主要负责环境感知中的road detection和路上目标识别。 road detection可以分为两大类：车道线检测和路面检测。在下面几节中，我们将回顾每个类型的主要工作。同时也会介绍一些深度学习的工作。如果要了解更多关于传统人工提取特征的方法，，可以参考后面几篇综述。

#### 车道线检测

车道线检测是识别路上的车道线以及估计车辆相对于检测到的车道线的相对位置。这些信息可以用于车辆的反馈控制。近十几年这方面有很多工作，但是这个问题还没有完整的解决方案。 由于实际中交通路面条件的不确定性，例如车辆和树木的阴影，多变的光照条件，磨损老化的车道线以及其他的交通标识例如方向箭头，警告字体，以及斑马线等，使得该问题极具挑战性。
大部分车道线检测系统包含三个主要步骤：（1）车道线特征提取，可以通过边缘检测，颜色，以及SVM等学习算法，或者boost分类器进行提取；（2）对检测到的像素点拟合不同的模型，例如直线，抛物线，双曲线，甚至之字形线；（3）基于拟合的车道线模型，估计车辆的相对位置。也可能在第三步之前会有一步时间整合步，以对暂时连续性进行限制。此时会使用滤波的方法利用当前的检测结果指导下一时刻的搜索范围，可能用到的滤波方法包括卡尔曼滤波，粒子滤波。
车道线特征提取是需要提取一些像素特征可以用于区分像素是否是车道线。现有文献中的大多数方法都是基于一个假设，即相比与路面，车道线有着明显的对比度。
文献中经常会使用一些基于梯度的方法，例如Soble边缘检测，梯度增强变换。但是这些算法对噪声敏感，并且阴影和杂物会引入大量的外点。此外，这些方法局限于局部的视野，忽略了车道线的形状特征。
文献中也有其他一些先进的基于图像梯度的变种，它们对噪声没有那么敏感。例如基于二维高斯的二阶导数的steerable filer。基于一阶导数tensor field construction 的 ridge detector。这些方法都可以将距离假设车道线比较远的梯度去除，从而得到正确的车道线梯度方向相应。
其他一些算法试图从一种不同的视角来检测车道线。例如在图像横向方向检测一种底-高-底的强度模式。最常用的方法是盒子滤波器（box filter）以及其他的一些变种。这些方法被认为比之前提到的方法更可靠。总的来说， 这种方法是用一种固定的捷越滤波器选择那些响应值比较高的像素点。准确的说这种方法是提取车道线中间线而不是边缘。
对于这种方法，需要根据车道线在图像中的大小控制好盒子滤波器的宽度，以防止过滤波或欠滤波。要不然就将原图像做inverse-perspective mapping以减小摄像头投影的影响。但是这仍然需要对摄像头的俯仰角进行良好的估计。与此同时，插值也经常被用于弥补逆投影变化中的像素丢失。随着距离的增加，插值的精度也会越来越低，为了解决这个问题，Du等提出了一种自适应的机制根据之前的宽度测量来在线更新滤波器宽度。
另一个缺陷和之前提到的车道线检测算法相同，都不能将车道线和其他一些路上的车道标识区分开，像警告语等。这些标识很容易误导最后的估计结果。

第二步是模型拟合。该部分是将前述方法检测到的像素点，提取出更简洁的高层次的车道表示方法。根据使用的模型不同，车辆的相对姿态可以通过模型拟合计算得出。这些模型可以用于指导下一时刻的车道线检测。
文献中提出了很多不同的车道线模型，可大致分为两类：参数化模型和半参数化模型。半参数化模型包括一些样条（splines），像B-Snake, Cubic splines active contours等。这些模型的优点在于它们足够灵活，能够覆盖不同道路的形状。但是，这种方法比较复杂，需要较多的计算资源。They also require a good  selection of control points. As concluded in [68], since there is no single model that can cover all kinds of road shapes, online model selection should be considered.
时间整合步是根据上一时刻的检测结果，指导当前时刻的检测。它强调了图像间的平滑性和连续性。可以提高车辆的位姿估计精度以及降低误检率。
提出的大部分方法都是随机的(stochastic)。例如卡尔曼滤波和粒子滤波。粒子滤波更可靠，尤其是在两帧图像的变化比较大时。
一般来说，粒子滤波可以直接用于图像像素，车道模型和车辆。例如在文献[80]中，每个粒子包含了图像中三次样条拟合关键点的位置。在文献[92, 102]中，每个粒子表示车道线模型参数。参数的变化简单假设为服从高斯分布。 然而，他们并没有提及协方差矩阵应该怎么获取。在文献[85]中，每个粒子表示车辆在真实世界的坐标位置，车辆运动仍然简单的假设为服从高斯分布。
最后一步是车道线级别的定位，用于估计车辆的纵向位置和相对于车道线的偏航角。为了从二维图像中恢复到三维世界中，深度是必须的。在大部分的方法中，深度是通过假设固定摄像头高度，以及地面平坦，根据摄像头视角或俯仰角来进行估计。一个经典的例子就是IPM（逆投影变换），但是它很大程度上取决于俯仰角以及对俯仰角的估计噪声敏感。
一个更直接并且可靠的方法是利用双目恢复深度。但是，该方案的问题在于，路面上纹理的单一性对双目获取差值图像造成了挑战。这也是双目在这个领域被广泛应用的主要原因。文献[108]利用一种稠密映射获取差值图，其中用到了最大后验-马尔科夫随机场方法。但是这些方法并不高效。考虑到这些缺点，Du提出了一种基于correspondence 匹配的车道线模型。

#### 路面检测
路面检测主要告诉自动驾驶系统，哪里可以行驶，哪里不可以行驶。它是路径规划的底层控制的前提。通常来说，路面检测的方法可以分为三大类：基于特征的检测，基于特征的学习，深度学习。
基于特征的检测方法首先根据预定义的特征（例如HOG）来识别图像中的特征点或者特征块。如果输入是双目图像，则特征一般是依赖于差值图。基于这些已识别的特征，可以用模型拟合或者分割的算法来识别道路平面。
文献[110]中在差值图使用了B-spline模型拟合算法来寻找道路平面。这些方法都是基于路面平坦的假设。之后也会经常使用卡尔曼滤波使结果更平滑。
除了使用模型拟合，将道路平面检测问题转化为条件随机场的优化问题也是一种方法。文献[111]中，作者将分类问题和稠密重建的任务相结合，构建了条件随机场的能量函数，这样可以提高每个单独任务的性能。
基于特征的学习方法通常是赋予每个像素点一组特征，然后基于这些特征训练一个分类器，以确定该像素点是不是属于路面。
文献[122]中提出了一种检测算法可以学习特征的纹理信息以提升图像块的分类能力。对于每个图像块，都会赋予两个辅助的图像块：一个是基于目标图像块周围预先定义模式的纹理块，一个是位于图像底部的道路块。然后从这三个图像块中提取出三个特征向量，最后合成一个特征向量。这个特征向量最后被送到多层感知机中做分类。这种方法的问题在于没有考虑全局信息以及选择道路块也是具有争议的，因为它是基于图像底部总会是道路的假设。
文献[113]提出了一种两级检测框架，它整合了场景的空间布局以处理复杂多变的场景。第一层包含了三个分类器，用于对道路边界，道路和车道线的分类。这三个分类器分开训练产生三个置信图。The spatial ray features that incorporate properties of the global environment are generated based on the confidence maps. Finally, a GentleBoost classifier was trained based on the spatial ray features.
文献[115, 116]中的分类器都使用了一个联合提升算法，整合基于纹理基元（filter-bank,颜色，HoG以及位置）和disptons(U-disptons和V-disptons)的特征映射。
然而上述提到的算法都是基于特征检测或者特征学习的算法，对于不确定的驾驶环境，这些方法并不鲁棒。
在KITTI数据集上，道路检测性能在前五名的算法均使用深度学习的方法。文献[119,120]使用图像块作为卷积网络的输入用于区分图像块的中心点是否是属于路面。在文献[120]中，作者还解释了如何把空间信息结合到CNN中，使学习的过程中具有空间先验。
不同于上面的两种方法，文献[121]提出了一种带有解卷积的网络结构，这个结构也用于multi-patch的训练，以学习到空间先验。这种方法也在KITTI数据集上取得了很好的效果。
尽管有着出色的性能，以及需要大量的标记数据，深度学习方法的缺点也是非常明显的：巨大的计算量以及内存要求，较长的处理时间，对内部过程无法分析。文献[122]提出一种网络结构以对计算时间和精度进行折中。它也使用了解卷积的结构，但是重新设计了类别和滤波器间映射，以减少运行时间。它将整张图片按照原分辨率进行输入，处理时间大约在50ms。
为了解决标记数据难的问题，文献[123]提出了一种地图监督的深度学习方法。在这种方法中，真实的标签数据是通过车辆的位置，朝向，摄像头参数，GPS,以及OpenStreeMap的数据确定的。通过像素外观特征来减少标记噪声。CNN网络使用这些生成的标记数据进行训练。

#### 路上目标检测
路上目标检测主要集中于检测车辆和行人。由于目标的种类，外观，形状以及尺寸的多样性，文献[71-73]中提到的方法都不够鲁棒，也不能够在自动驾驶中广泛应用。在KITTI数据集上，对车辆，行人以及自行车的检测都是基于深度学习的。相比于传统的学习方法以及基于特征的方法，深度学习算法拥有绝对优势。因此，这一章也主要介绍基于深度学习的方法。
